### LSM tree 


日志结构合并树(log-structured merge tree, LSM tree)及其变体是对 `B+` 树[^1]的写操作优化进行的一种索引结构，在各种数据库系统实现上被广泛采用，例如 `MySQL` 的存储引擎 `MyRocks` ， 嵌入式数据库 `SQLite4` 和 `LevelDB`。

[^1]:并不一定是B+树。但是需要是有序的数据结构，如SSTable。

#### 为什么需要对B+树的写操作进行优化？

既然LSM tree是对B+树的写操作进行优化，那么说明B+树的写操作的性能有待提高，实际上B+在随机写操作上的性能表现可能相当差劲。下面我们来说明对于需要支持每秒大量随机写/插入的应用程序来说，使用基本的B+树索引结构得效果并不理想。

考虑B+索引太大,无法装入内存的情形，由于叶子页面占据了大部分空间，而且现在的内存大小也相当大了，为了简单起见，我们假设除叶子页面的内部页面的更高级别的索引都能放入内存。

现在假设写入或插入的顺序与索引的排序顺序不匹配。这样的话，每个写入/插入都可能访问不同的叶节点，如果叶节点的数量明显大于缓冲区大小，那么大多数这些叶访问将需要一个随机读操作以及后续将更新后的叶页写回磁盘写操作。在访问时间为10ms的磁盘的系统上，B+索引只能支持每个磁盘每秒不超过100次写/插入; 这当然是一个相对乐观的估计，因为我们假设寻道(seek)占用了大量的时间，并且磁头在读和写叶子页之间进行没有移动。即使在基于闪存的SSDs的系统上，随机I/O速度要快得多，但是写页面仍然有很大的成本，因为它(最终)需要擦除页面，这是一项昂贵的操作。

#### LSM树的结构

`LSM` 树 由几个 `B+` 树组成，首先是内存树，称为 $L_0$，然后是磁盘树 $L_1, L_2，…，L_k$ ，其中 $k$ 称为层。下图描述了 $k = 3$ 时 `LSM` 树的结构。

![lsmtree](lsmtree.svg)

#### LSM树上的操作

##### 查找
查找是通过对每个树$L_0, ..., L_k$使用单独的查找操作，并合并查找结果来执行的。(我们假设现在只有插入，没有更新或删除;出现更新/删除时的索引查找更加复杂，稍后将讨论。)

##### 插入

当一条记录第一次插入到 `LSM` 树中时，这条记录首先被插入到内存 `B+` 树结构 $L_0$。相当大的内存空间被分配给该树，当处理更多的插入时，树就会增长，直到它填满分配给它的内存为止。此时，我们需要将数据从内存结构移动到磁盘上的 `B+` 树。

如果树 $L_1$ 为空，则将整个内存树 $L_0$ 写入磁盘，以创建初始树 $L_1$。但如果 $L_1$ 不为空，则 $L_0$ 按关键字递增的顺序扫描叶子页面上的记录，并与 $L_1$ 的叶子页面上的记录合并(也是按关键字递增的顺序扫描)。合并的后的记录使用自底向上的方法创建一个新的 `B+` 树。然后，合并后的新树将替换旧树 $L_1$。在这两种情况下，当 $L_0$ 的记录被移动到$L_1$之后，$L_0$ 中的所有记录以及旧的$L_1$(如果存在的话)都被删除。然后可以对内存中现在为空的$L_0$进行插入。

###### Append Only 而不是 In-palce Update  的好处与坏处
注意，旧 $L_1$ 树的叶子层中的所有记录，包括那些没有任何更新的叶子节点，都被复制到新树中，而不是对现有的$L_1$树节点执行更新。这带来了以下好处：
  
1. 新树的叶子按顺序定位，避免在随后的合并过程中出现随机I/O。
2. 叶节点是满的，避免了部分占用叶节点的开销，这可能会导致分页


但是，使用如上所述的 `LSM` 结构是有代价的:每次将 $L_0$ 中的一组记录复制到 $L_1$ 时，都要复制树的整个内容。有两种方法可以降低成本:

###### 基本LSM树上的写优化策略： 设置多个level 和每个level设置棵树

1. 使用了多个级别，$L_{i+1}$ 级树的最大大小是$L_i$级树最大大小的 $k$倍。因此，在特定的级别上，每条记录最多被写入 $k$ 次。级别的个数与 $log_k(I/M)$ 成比例，其中 $I$是记录的数量，$M$是能放入内存树$L_0$的记录的数量。
2. 每个`level`(除了$L_0$)最多可以有$b$棵树，而不是1棵。当$L_0$树写入磁盘时，将创建一个新的$L_1$树，而不是将其与现有的$L_1$树合并。当有$b$棵这样的$L_1$树时，它们合并成一棵新的$L_2$树。类似地，当$L_i$有$b$棵树时，它们会合并成一棵新的$L_{i+1}$树。
    LSM树的这种变体称为步进合并索引（`stepped-merge index`）。与每个级别只有一棵树相比，步进合并索引显著降低了插入成本，但它可能导致查询成本增加，因为可能需要搜索多棵树。基于位图的结构称为布隆过滤器（`bloom filter`），通过有效地检测特定树中不存在搜索键，用来减少查找的次数。布隆过滤器占用的空间很小，但它们在降低查询成本方面非常有效。


![stepped-mergeIndex](stepped-mergeIndex.svg)


##### 删除

删除以一种有趣的方式处理。不是直接找到索引项并删除它，而是删除操作是插入一个新的标记删除记录，该标记删除记录指向待删除的索引记录。插入删除标记记录的过程与插入普通索引记录的过程相同。

然而，查找必须执行一个额外的步骤。如前所述，查找操作从所有树中检索记录，并按键值排序将它们合并。*如果某个记录有一个删除记录，它们将具有相同的键值*。因此，查找操作将同时找到该键的删除记录和要删除的原始记录。如果找到了删除记录，将过滤掉要删除的记录，而不作为查找结果的一部分返回。

当树被合并时，如果其中一棵树包含一个记录，而另一棵树有一个匹配的删除记录，那么这些记录在合并过程中会被匹配(*它们都有相同的键*)，并且都会被丢弃。

##### 更新

通过插入更新记录，以类似于删除的方式处理更新。查找需要将更新记录与原始记录进行匹配，并返回最新的值。当一个树有一个记录而另一个树有它的匹配的更新记录时，更新实际上是在合并期间应用的;合并过程将找到具有相同键的记录和更新记录，应用更新，并丢弃更新记录。


#### LSM树在磁盘和SSD存储介质上的不同性能表现

LSM树最初的设计是为了减少磁盘的写和查找开销。基于Flash的ssd对于随机I/O操作的开销相对较低，因为它们不需要查找，因此避免LSM树变体提供的随机I/O的好处对于ssd来说不是特别重要。

但是，回想一下，闪存不允许就地更新，即使向页面写入一个字节，也需要将整个页面重写到一个新的物理位置;页面的原始位置最终需要删除，这是一个相对昂贵的操作。与传统的B+树相比，使用LSM树变体可以减少写操作的数量，当LSM树与ssd一起使用时，可以提供显著的性能优势


#### LSM树在分布式文件系统和大数据存储系统上的应用

在谷歌的BigTable系统以及Apache HBase (BigTable的开源克隆)中使用了LSM树的一个变体，类似于步进合并索引，每一层都有多个树。这些系统构建在分布式文件系统之上，分布式文件系统允许对文件进行追加，但不支持对现有数据的更新。LSM树不执行原地更新的事实使LSM树非常适合这些系统。

后，大量的BigData存储系统(如Apache Cassandra、Apache AsterixDB和MongoDB)增加了对LSM树的支持，大多数实现版本在每一层都有多个树。


#### 总结和补充说明

1. LSM树的结构又一次体现了系统设计里面的trade-off, 为了能够得到最大的写入能力，不得不牺牲就部分读的性能。

#### 参考文献

1. [Database System Concepts(Seventh Edition, Avi Silberschatz Henry F. KorthS. Sudarshan)](https://www.db-book.com/db7/index.html)